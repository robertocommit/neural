{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House-prices: advanced-regression-techniques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZVJmJbhB3ZqzPZlLl9Wa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robimalco/colab/blob/main/House_prices_advanced_regression_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHjvM2-hXK0H"
      },
      "source": [
        "## Download files\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZIbwZHoYg96"
      },
      "source": [
        "- **SalePrice** - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
        "- **1stFlrSF**: First Floor square feet\n",
        "- **2ndFlrSF**: Second floor square feet\n",
        "- **3SsnPorch**: Three season porch area in square feet\n",
        "- **Alley**: Type of alley access\n",
        "- **Bedroom**: Number of bedrooms above basement level\n",
        "- **BldgType**: Type of dwelling\n",
        "- **BsmtCond**: General condition of the basement\n",
        "- **BsmtExposure**: Walkout or garden level basement walls\n",
        "- **BsmtFinSF1**: Type 1 finished square feet\n",
        "- **BsmtFinSF2**: Type 2 finished square feet\n",
        "- **BsmtFinType1**: Quality of basement finished area\n",
        "- **BsmtFinType2**: Quality of second finished area (if present)\n",
        "- **BsmtFullBath**: Basement full bathrooms\n",
        "- **BsmtHalfBath**: Basement half bathrooms\n",
        "- **BsmtQual**: Height of the basement\n",
        "- **BsmtUnfSF**: Unfinished square feet of basement area\n",
        "- **CentralAir**: Central air conditioning\n",
        "- **Condition1**: Proximity to main road or railroad\n",
        "- **Condition2**: Proximity to main road or railroad (if a second is present)\n",
        "- **Electrical**: Electrical system\n",
        "- **EnclosedPorch**: Enclosed porch area in square feet\n",
        "- **ExterCond**: Present condition of the material on the exterior\n",
        "- **Exterior1st**: Exterior covering on house\n",
        "- **Exterior2nd**: Exterior covering on house (if more than one material)\n",
        "- **ExterQual**: Exterior material quality\n",
        "- **Fence**: Fence quality\n",
        "- **FireplaceQu**: Fireplace quality\n",
        "- **Fireplaces**: Number of fireplaces\n",
        "- **Foundation**: Type of foundation\n",
        "- **FullBath**: Full bathrooms above grade\n",
        "- **Functional**: Home functionality rating\n",
        "- **GarageArea**: Size of garage in square feet\n",
        "- **GarageCars**: Size of garage in car capacity\n",
        "- **GarageCond**: Garage condition\n",
        "- **GarageFinish**: Interior finish of the garage\n",
        "- **GarageQual**: Garage quality\n",
        "- **GarageType**: Garage location\n",
        "- **GarageYrBlt**: Year garage was built\n",
        "- **GrLivArea**: Above grade (ground) living area square feet\n",
        "- **HalfBath**: Half baths above grade\n",
        "- **Heating**: Type of heating\n",
        "- **HeatingQC**: Heating quality and condition\n",
        "- **HouseStyle**: Style of dwelling\n",
        "- **Kitchen**: Number of kitchens\n",
        "- **KitchenQual**: Kitchen quality\n",
        "- **LandContour**: Flatness of the property\n",
        "- **LandSlope**: Slope of property\n",
        "- **LotArea**: Lot size in square feet\n",
        "- **LotConfig**: Lot configuration\n",
        "- **LotFrontage**: Linear feet of street connected to property\n",
        "- **LotShape**: General shape of property\n",
        "- **LowQualFinSF**: Low quality finished square feet (all floors)\n",
        "- **MasVnrArea**: Masonry veneer area in square feet\n",
        "- **MasVnrType**: Masonry veneer type\n",
        "- **MiscFeature**: Miscellaneous feature not covered in other categories\n",
        "- **MiscVal**: $Value of miscellaneous feature\n",
        "- **MoSold**: Month Sold\n",
        "- **MSSubClass**: The building class\n",
        "- **MSZoning**: The general zoning classification\n",
        "- **Neighborhood**: Physical locations within Ames city limits\n",
        "- **OpenPorchSF**: Open porch area in square feet\n",
        "- **OverallCond**: Overall condition rating\n",
        "- **OverallQual**: Overall material and finish quality\n",
        "- **PavedDrive**: Paved driveway\n",
        "- **PoolArea**: Pool area in square feet\n",
        "- **PoolQC**: Pool quality\n",
        "- **RoofMatl**: Roof material\n",
        "- **RoofStyle**: Type of roof\n",
        "- **SaleCondition**: Condition of sale\n",
        "- **SaleType**: Type of sale\n",
        "- **ScreenPorch**: Screen porch area in square feet\n",
        "- **Street**: Type of road access\n",
        "- **TotalBsmtSF**: Total square feet of basement area\n",
        "- **TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)\n",
        "- **Utilities**: Type of utilities available\n",
        "- **WoodDeckSF**: Wood deck area in square feet\n",
        "- **YearBuilt**: Original construction date\n",
        "- **YearRemodAdd**: Remodel date\n",
        "- **YrSold**: Year Sold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikpSo7hJMLv7"
      },
      "source": [
        "# Configure and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQPvQcB_Tp7Q"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA-nbClRO8ir"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_YOUDwLudyM"
      },
      "source": [
        "!pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip3 install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ8LXcTzXUW6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpcjl4q4uPXv"
      },
      "source": [
        "# !nvcc --version\n",
        "# !python --version\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXgfdGs0_AA"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX-8bRYWXmRK"
      },
      "source": [
        "original_train_df = pd.read_csv('train.csv')\n",
        "original_train_df['Source'] = 'train.csv'\n",
        "\n",
        "original_test_df = pd.read_csv('test.csv')\n",
        "original_test_df['Source'] = 'test.csv'\n",
        "\n",
        "total_df = pd.concat([original_train_df, original_test_df], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFtZcutli20l"
      },
      "source": [
        "numerical_columns = []\n",
        "categorical_columns = []\n",
        "\n",
        "for column in total_df.columns:\n",
        "  if total_df.dtypes[column] == np.int64 or total_df.dtypes[column] == np.float64:\n",
        "    numerical_columns.append(column)\n",
        "  else:\n",
        "    categorical_columns.append(column)\n",
        "\n",
        "categorical_columns.remove('Source')\n",
        "numerical_columns.remove('SalePrice')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYARgnvfcjvB"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHaEmcvpHY77"
      },
      "source": [
        "list_of_numerics = total_df.select_dtypes(include=['float', 'int']).columns\n",
        "corrSalePrice = round(total_df[numerical_columns].corrwith(original_train_df['SalePrice']), 3) * 100\n",
        "types = total_df.dtypes\n",
        "missing = round((total_df.isnull().sum()/total_df.shape[0]),3)*100\n",
        "overview = total_df.apply(\n",
        "    lambda x: [\n",
        "      round(x.min()), \n",
        "      round(x.max()), \n",
        "      round(x.mean()), \n",
        "      round(x.quantile(0.5))\n",
        "    ] if x.name in list_of_numerics else x.unique())\n",
        "outliers = total_df.apply(\n",
        "    lambda x: sum(\n",
        "        (x<(x.quantile(0.25)-1.5*(x.quantile(0.75)-x.quantile(0.25)))) | \n",
        "        (x>(x.quantile(0.75)+1.5*(x.quantile(0.75)-x.quantile(0.25)))) \n",
        "      if x.name in list_of_numerics else ''))\n",
        "explore_df = pd.DataFrame({\n",
        "  'Types': types,\n",
        "  'CorrSalePrice%': corrSalePrice,\n",
        "  'Missing%': missing,\n",
        "  'Overview': overview,\n",
        "  'Outliers': outliers\n",
        "})\n",
        "explore_df['Types'] = explore_df['Types'].astype(str)\n",
        "explore_df.sort_values(by=['Missing%'], ascending=False).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZxFoKoeclW_"
      },
      "source": [
        "# Plot Correlation Matrix\n",
        "\n",
        "temp_df = total_df[numerical_columns]\n",
        "f = plt.figure(figsize=(19, 15))\n",
        "plt.matshow(temp_df.corr(), fignum=f.number)\n",
        "plt.xticks(range(temp_df.shape[1]), temp_df.columns, fontsize=14, rotation=45)\n",
        "plt.yticks(range(temp_df.shape[1]), temp_df.columns, fontsize=14)\n",
        "cb = plt.colorbar()\n",
        "cb.ax.tick_params(labelsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFK6gHFHaZ1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoUnfrYHWbVY"
      },
      "source": [
        "# Manage missing values\n",
        "# Based on the number of missing values, \n",
        "# decide if makes sense or not to create a dedicated category called \"None\",\n",
        "# or if it is simply better to assign a mean() value\n",
        "\n",
        "for column in ['Alley', 'MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1', 'BsmtFinType2','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']:\n",
        "  total_df[column] = total_df[column].fillna('None')\n",
        "for column in ['Electrical','MSZoning','Exterior1st','Exterior2nd','KitchenQual','SaleType','Functional', 'Utilities']:\n",
        "  total_df[column] = total_df[column].fillna(total_df[column].mode()[0])\n",
        "for column in ['MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath', 'GarageYrBlt','GarageCars','GarageArea']:\n",
        "  total_df[column] = total_df[column].fillna(0)\n",
        "for column in ['LotFrontage']:\n",
        "  total_df[column] = total_df[column].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAc38PlBbMjR"
      },
      "source": [
        "# Remove outsiders\n",
        "\n",
        "total_df = total_df[total_df['GrLivArea'] < 4000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka9b57nUXRdm"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H7dGWda4b9D"
      },
      "source": [
        "# GarageYrBlt\n",
        "# MiscVal\n",
        "# Id\n",
        "# YrSold \n",
        "# BsmtHalfBath\n",
        "# numerical_columns.remove('GarageYrBlt')\n",
        "# numerical_columns.remove('MiscVal')\n",
        "# numerical_columns.remove('Id')\n",
        "# numerical_columns.remove('YrSold')\n",
        "# numerical_columns.remove('BsmtHalfBath')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuXoQGkh6I21"
      },
      "source": [
        "cp_total_df = total_df\n",
        "# cp_total_df = cp_total_df.drop(['Id'], axis=1)\n",
        "# cp_total_df = cp_total_df.drop(['GarageYrBlt', 'MiscVal', 'Id', 'YrSold', 'BsmtHalfBath'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X84hwInAlSsV"
      },
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "for column in categorical_columns:\n",
        "  cp_total_df[column] = LabelEncoder().fit_transform(cp_total_df[column])\n",
        "\n",
        "for column in categorical_columns:\n",
        "  cp_total_df[column] = cp_total_df[column].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_GlBfjTshPZ"
      },
      "source": [
        "train_df = cp_total_df[cp_total_df['Source'] == 'train.csv']\n",
        "train_output_df = pd.DataFrame(train_df['SalePrice'], columns=['SalePrice'])\n",
        "train_df.drop('SalePrice', axis=1, inplace=True)\n",
        "test_df = cp_total_df[cp_total_df['Source'] == 'test.csv']\n",
        "test_df.drop('SalePrice', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWct8Lc5u76g"
      },
      "source": [
        "def create_tensor(input_df):\n",
        "  stack = []\n",
        "  for column in categorical_columns:\n",
        "    temp_stack = input_df[column].cat.codes.values\n",
        "    stack.append(temp_stack)\n",
        "  for column in numerical_columns:\n",
        "    temp_stack = input_df[column].astype(np.float64)\n",
        "    stack.append(temp_stack)\n",
        "  return torch.tensor(np.stack(stack, 1), dtype=torch.float)\n",
        "\n",
        "\n",
        "tensor_train = create_tensor(train_df).float()\n",
        "tensor_output = torch.tensor(train_output_df.values).flatten().float()\n",
        "\n",
        "tensor_test = create_tensor(test_df).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWd-cmIqYSi"
      },
      "source": [
        "total_records_train = len(tensor_train)\n",
        "test_records_train = int(total_records_train * 0.2)\n",
        "\n",
        "tensor_train_data = tensor_train[:total_records_train-test_records_train]\n",
        "tensor_train_output = tensor_output[:total_records_train-test_records_train]\n",
        "\n",
        "tensor_validation_data = tensor_train[total_records_train-test_records_train:total_records_train]\n",
        "tensor_validation_output = tensor_output[total_records_train-test_records_train:total_records_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN_8pJnLv46m"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(len(tensor_train_data[1].to(device)), 1000)\n",
        "    self.linear2 = nn.Linear(1000, 500)\n",
        "    self.linear3 = nn.Linear(500, 200)\n",
        "    self.linear4 = nn.Linear(200, 1)\n",
        "  def forward(self, x):\n",
        "    y = self.linear1(x)\n",
        "    y = torch.nn.functional.dropout(y, p=0.2)\n",
        "    y = self.linear2(y)\n",
        "    y = torch.nn.functional.dropout(y, p=0.2)\n",
        "    y = self.linear3(y)\n",
        "    y = torch.nn.functional.dropout(y, p=0.2)\n",
        "    y = self.linear4(y)\n",
        "    return y"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAP1r8NfyE0U"
      },
      "source": [
        "model = Model()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY4iolXgyYDh"
      },
      "source": [
        "def train_model(fold, epochs, x, y, aggregated_losses):\n",
        "  for i in range(epochs):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_function(y_pred.squeeze(), y)\n",
        "    optimizer.zero_grad() # sets the gradients of all optimized to zero.\n",
        "    loss.backward() # compute gradient of loss with respect to all the parameters\n",
        "    optimizer.step() # iterate and update all parameters based on the current gradient\n",
        "    if i == epochs - 1:\n",
        "      print(\"fold:\", fold, \"epoch: \" + str(i) + \"\\tloss: \" + str(loss.item()))\n",
        "    aggregated_losses.append(loss)"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ka0sg11kDSF"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "epochs = 300\n",
        "aggregated_losses = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(tensor_train_data, tensor_train_output)):\n",
        "  x_train_fold = tensor_train_data[train_index].to(device)\n",
        "  y_train_fold = tensor_train_output[train_index].to(device)\n",
        "  train_model(fold, epochs, x_train_fold, y_train_fold, aggregated_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVToMBNREwCj"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range(0, len(aggregated_losses)), aggregated_losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JYu0awluUfb"
      },
      "source": [
        "# Overfitting if: training loss << validation loss\n",
        "# Underfitting if: training loss >> validation loss\n",
        "# Just right if training loss ~ validation loss\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_validation = tensor_validation_data.to(device)\n",
        "    y_validation = tensor_validation_output.to(device)\n",
        "    y_val = model(x_validation)\n",
        "    loss_validation = loss_function(y_val.squeeze(), y_validation)\n",
        "print(\"Validation loss: \", str(loss_validation.item()))\n",
        "print(\"Train Loss VS Validation loss: \", round(1 - aggregated_losses[len(aggregated_losses) - 1].item() / loss_validation.item(), 2) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vsGovLYKV9f"
      },
      "source": [
        "aggregated_losses[len(aggregated_losses) - 1].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDOnUS8-ksLD"
      },
      "source": [
        "# To remove overfitting\n",
        "#   Cross-validation: use your initial training data to generate multiple mini train-test splits.\n",
        "#   Remove features: removing irrelevant input features or aggregate them \n",
        "#   Early stopping: stopping the training process before the learner degradates.\n",
        "#   Regularization: adds a penalty as model complexity increases\n",
        "#   Ensembling: machine learning methods for combining predictions from multiple separate models. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMS8A0eVuyZN"
      },
      "source": [
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    x_test = tensor_test.to(device)\n",
        "    y_pred = model(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g94fE8ma2Ek7"
      },
      "source": [
        "submission_df = pd.DataFrame(y_pred, columns=['SalePrice']).astype(\"float\")\n",
        "\n",
        "submission_df = pd.concat([original_test_df, submission_df], axis=1)\n",
        "\n",
        "submission_df = submission_df[['Id', 'SalePrice']]\n",
        "\n",
        "# submission_df[submission_df['Id'] == 2891]\n",
        "submission_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjKkery93hzJ"
      },
      "source": [
        "submission_df.iloc[len(submission_df)-1, submission_df.columns.get_loc('SalePrice')] = 244171.2813"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rODwWm9uJ5Ml",
        "outputId": "066ab6f8-1c4d-403b-b6ad-80b8df00baaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_217f16b1-e27c-447e-a25f-ef283540ffe9\", \"submission.csv\", 26463)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}