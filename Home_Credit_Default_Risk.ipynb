{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Home Credit Default Risk",
      "provenance": [],
      "collapsed_sections": [
        "s933KG08D48G"
      ],
      "authorship_tag": "ABX9TyMhu5oP63QEdas//IdV3or5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robimalco/colab/blob/main/Home_Credit_Default_Risk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N9Cm7RzTvoY"
      },
      "source": [
        "# ADD KEYS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPDViyQqPsaM"
      },
      "source": [
        "!rm -rf *\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"robimalco\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"0f4600b98146814d7a153f58c4cf4389\" # key from the json file\n",
        "!pip install -q kaggle\n",
        "!kaggle competitions download -c home-credit-default-risk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdr6gDQq5rET"
      },
      "source": [
        "# START SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KnrADYj7yUe"
      },
      "source": [
        "!unzip application_test.csv.zip\n",
        "!unzip application_train.csv.zip\n",
        "# !unzip POS_CASH_balance.csv.zip\n",
        "# !unzip bureau.csv.zip\n",
        "# !unzip bureau_balance.csv.zip\n",
        "# !unzip credit_card_balance.csv.zip\n",
        "# !unzip installments_payments.csv.zip\n",
        "# !unzip previous_application.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbHvWyux-QjF"
      },
      "source": [
        "!pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import string\n",
        "letters = string.ascii_lowercase"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWBMpGHRRgn-"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mGDv_sUBXxI"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnY9FfmTaHux"
      },
      "source": [
        "!pip install --upgrade gspread\n",
        "from google.colab import auth, drive\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "drive.mount('/drive')\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1M-CqsTbBu7ScY4mZBcpI8kPbI7F-BE8aPTC4UknumYk/edit#gid=0')\n",
        "sheet = wb.worksheet('Data')\n",
        "def get_next_row(worksheet):\n",
        "    str_list = list(filter(None, worksheet.col_values(1)))\n",
        "    return str(len(str_list)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ4CWCK1cvvb"
      },
      "source": [
        "# SET HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xgR3YWAcuZk"
      },
      "source": [
        "hp_test_size = 0.2\n",
        "hp_emb_drop = 0.04\n",
        "hp_layers = [800, 300]\n",
        "hp_ps = [0.001,0.01]\n",
        "hp_lr= 0.001\n",
        "hp_epochs = 4"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxeWyJnq58bz"
      },
      "source": [
        "# Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F40xkOit6Df6"
      },
      "source": [
        "*   application_{train|test}.csv --> main table, static data for all applications. One row represents one loan in our data sample.\n",
        "*   bureau.csv -->  client's previous credits, for every loan in our sample, there are as many rows as number of credits the client had.\n",
        "*   bureau_balance.csv --> monthly balances of previous credits, one row for each month.\n",
        "*   POS_CASH_balance.csv --> monthly balance snapshots of previous point of sales and cash loans that the applicant had, one row for each month.\n",
        "*   credit_card_balance.csv --> monthly balance snapshots of previous credit cards, one row for each month.\n",
        "*   previous_application.csv --> all previous applications for Home Credit loans of clients who have loans.\n",
        "*   installments_payments.csv --> repayment history for the previously disbursed credits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iS2krKz9hVR"
      },
      "source": [
        "# LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoAxsP_l9glq"
      },
      "source": [
        "application_train_df = pd.read_csv('application_train.csv').sample(frac = 1)\n",
        "application_test_df = pd.read_csv('application_test.csv')\n",
        "# bureau_df = pd.read_csv('bureau.csv')\n",
        "# bureau_balance_df = pd.read_csv('bureau_balance.csv')\n",
        "# pos_cash_balance_df = pd.read_csv('POS_CASH_balance.csv')\n",
        "# credit_card_balance_df = pd.read_csv('credit_card_balance.csv')\n",
        "# previous_application_df = pd.read_csv('previous_application.csv')\n",
        "# installments_payments_df = pd.read_csv('installments_payments.csv')"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxIIM5xLxla9"
      },
      "source": [
        "# application_train_df = application_train_df.head(round(application_train_df.shape[0] * 0.5))\n",
        "# application_test_df = application_test_df.head(round(application_test_df.shape[0] * 0.3))"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp3mbkvTIboq"
      },
      "source": [
        "application_train_df['CSV_SOURCE'] = 'application_train.csv'\n",
        "application_test_df['CSV_SOURCE'] = 'application_test.csv'\n",
        "df = pd.concat([application_train_df, application_test_df])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s933KG08D48G"
      },
      "source": [
        "# UTILITIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1r_TCDSbOWB"
      },
      "source": [
        "def generate_timestamp():\n",
        "  now = datetime.datetime.now()\n",
        "  year = '{:02d}'.format(now.year)\n",
        "  month = '{:02d}'.format(now.month)\n",
        "  day = '{:02d}'.format(now.day)\n",
        "  hour = '{:02d}'.format(now.hour)\n",
        "  minute = '{:02d}'.format(now.minute)\n",
        "  return '{}-{}-{} {}:{}'.format(year, month, day, hour, minute)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhVH--sUJ9u"
      },
      "source": [
        "def order_columns_alphabetically(input_df):\n",
        "  input_df_columns = list(input_df.columns)\n",
        "  input_df_columns.sort()\n",
        "  return input_df[input_df_columns]"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMpsQ-_X-996"
      },
      "source": [
        "def split_columns_by_type(input_df):\n",
        "  numerical_columns = []\n",
        "  categorical_columns = []\n",
        "  for column in input_df.columns:\n",
        "    if input_df.dtypes[column] == np.int64 or input_df.dtypes[column] == np.float64:\n",
        "      numerical_columns.append(column)\n",
        "    else:\n",
        "      categorical_columns.append(column)\n",
        "  return numerical_columns, categorical_columns"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ThF3xmfqKU"
      },
      "source": [
        "# threshold = 60\n",
        "def convert_numerical_to_categorical(input_df):\n",
        "  for column in input_df.columns:\n",
        "    if column == 'TARGET':\n",
        "      pass\n",
        "    elif input_df.dtypes[column] == np.int64 or input_df.dtypes[column] == np.float64:\n",
        "      if len(input_df[column].unique()) < 60:\n",
        "        input_df[column] = input_df[column].astype('string')\n",
        "  return input_df"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYbnyF3dTGWo"
      },
      "source": [
        "def smart_overview(input_df):\n",
        "  a_types = []\n",
        "  a_countUnique = []\n",
        "  a_missing = []\n",
        "  a_missing_perc = []\n",
        "  a_corrTarget = []\n",
        "  a_min = []\n",
        "  a_max = []\n",
        "  a_mean = []\n",
        "  a_median = []\n",
        "  a_quantile = []\n",
        "  for column in input_df.columns:\n",
        "    x = input_df[column]\n",
        "    x_type = input_df.dtypes[column]\n",
        "    countUnique = len(x.unique())\n",
        "    missing = x.isnull().sum()\n",
        "    missing_perc = round((missing/input_df.shape[0]),3)*100\n",
        "    if x_type == np.int64 or x_type == np.float64:\n",
        "      a_corrTarget.append(round(x.corr(input_df['TARGET']), 3))\n",
        "      a_min.append(x.min())\n",
        "      a_max.append(x.max())\n",
        "      a_mean.append(x.mean())\n",
        "      a_median.append(x.median())\n",
        "      a_quantile.append(x.quantile(0.5))\n",
        "    else:\n",
        "      a_corrTarget.append('')\n",
        "      a_min.append('')\n",
        "      a_max.append('')\n",
        "      a_mean.append('')\n",
        "      a_median.append('')\n",
        "      a_quantile.append('')\n",
        "    a_types.append(x_type)\n",
        "    a_countUnique.append(countUnique)\n",
        "    a_missing.append(missing)\n",
        "    a_missing_perc.append(missing_perc)\n",
        "  explore_df = pd.DataFrame({\n",
        "    'Columns': input_df.columns,\n",
        "    'Types': a_types,\n",
        "    'Unique': a_countUnique,\n",
        "    'Missing': a_missing,\n",
        "    'Missing%': a_missing_perc,\n",
        "    'CorrTarget': a_corrTarget,\n",
        "    'Min': a_min,\n",
        "    'Max': a_max,\n",
        "    'Mean': a_mean,\n",
        "    'Median': a_median,\n",
        "    'Quantile': a_quantile\n",
        "  })\n",
        "  explore_df.set_index('Columns', inplace=True)\n",
        "  return explore_df.transpose()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmxzAril9NMB"
      },
      "source": [
        "# MANAGE COLUMNS (NUMERICAL VS CATEGORICAL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2m7uNvWyHA2"
      },
      "source": [
        "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].apply(lambda x: abs(round(x / 2000))).astype('string')\n",
        "df['DAYS_ID_PUBLISH'] = df['DAYS_ID_PUBLISH'].apply(lambda x: abs(round(x / 2000))).astype('string')\n",
        "df['DAYS_REGISTRATION'] = df['DAYS_REGISTRATION'].apply(lambda x: abs(round(x / 2000))).astype('string')"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTJtbRPtDRn9"
      },
      "source": [
        "df = order_columns_alphabetically(df)\n",
        "df = convert_numerical_to_categorical(df)\n",
        "columns_type = split_columns_by_type(df)\n",
        "numerical_columns = columns_type[0]\n",
        "categorical_columns = columns_type[1]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEy-9Qsz7ZoM"
      },
      "source": [
        "numerical_columns = ['AMT_ANNUITY', 'AMT_CREDIT', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE']\n",
        "categorical_columns = ['CODE_GENDER', 'CSV_SOURCE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION']\n",
        "target_column = ['TARGET']"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPTBqQsV8VUB"
      },
      "source": [
        "df = df[numerical_columns + categorical_columns + target_column]"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDybyT2XAc5P"
      },
      "source": [
        "smart_overview(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l96wo_5oYYA3"
      },
      "source": [
        "# MANAGE MISSING VALUES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2j9zI7mHBoP"
      },
      "source": [
        "for numerical_column in numerical_columns:\n",
        "  df[numerical_column].fillna(value=df[numerical_column].median(), inplace=True)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeMm7CCwYgi0"
      },
      "source": [
        "# STANDARDISE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT7t1r068wJX"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "df[numerical_columns] = pd.DataFrame(min_max_scaler.fit_transform(df[numerical_columns]))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66MJfs5ZBUC"
      },
      "source": [
        "# CONVERT CATEGORICAL COLUMNS INTO TYPE \"CATEGORY\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Hv3Ii6DWMx"
      },
      "source": [
        "categorical_columns.remove('CSV_SOURCE')\n",
        "\n",
        "for column in categorical_columns:\n",
        "  df[column] = LabelEncoder().fit_transform(df[column].astype(str))\n",
        "  df[column] = df[column].astype('category')"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lmf7AyiaqGL"
      },
      "source": [
        "# SPLIT DATA INTO TRAINING vs TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6lrtUpJan-"
      },
      "source": [
        "train_df = df[df['CSV_SOURCE'] == 'application_train.csv']\n",
        "train_output_df = pd.DataFrame(train_df['TARGET'], columns=['TARGET'])\n",
        "\n",
        "test_df = df[df['CSV_SOURCE'] == 'application_test.csv']"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7yzRWz9a-UZ"
      },
      "source": [
        "# REMOVE NOT USEFUL COLUMNS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJ3_8sMbC_U"
      },
      "source": [
        "train_df.drop(columns=['CSV_SOURCE', 'TARGET'], axis=0, inplace=True)\n",
        "test_df.drop(columns=['CSV_SOURCE', 'TARGET'], axis=0, inplace=True)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9XyQsFRcpSZ"
      },
      "source": [
        "# CREATE VALIDATION SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isjke6nLcV2G"
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train_df, train_output_df, test_size=hp_test_size, random_state=42)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV5OXy6FbTUR"
      },
      "source": [
        "# CREATE TENSORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm8ZS9Lidh3R"
      },
      "source": [
        "def create_tensors(input_df):\n",
        "  stack = []\n",
        "  for column in input_df.columns:\n",
        "    if input_df.dtypes[column] == np.int64 or input_df.dtypes[column] == np.float64:\n",
        "      stack.append(input_df[column].astype(np.float64))\n",
        "    else:\n",
        "      stack.append(input_df[column].cat.codes.values)\n",
        "  return torch.tensor(np.stack(stack, 1), dtype=torch.float)\n",
        "\n",
        "tensor_x_train_cat = create_tensors(x_train[categorical_columns]).float().to(device)\n",
        "tensor_x_train_num = create_tensors(x_train[numerical_columns]).float().to(device)\n",
        "tensor_y_train = torch.tensor(y_train.values).flatten().float().to(device)\n",
        "\n",
        "tensor_x_valid_cat = create_tensors(x_validation[categorical_columns]).float().to(device)\n",
        "tensor_x_valid_num = create_tensors(x_validation[numerical_columns]).float().to(device)\n",
        "tensor_y_valid = torch.tensor(y_validation.values).flatten().float().to(device)\n",
        "\n",
        "tensor_x_test_cat = create_tensors(test_df[categorical_columns]).float().to(device)\n",
        "tensor_x_test_num = create_tensors(test_df[numerical_columns]).float().to(device)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaRUVJlngYeT"
      },
      "source": [
        "# CREATE CATEGORICAL EMBEDDING SIZES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDav1gcL2MN"
      },
      "source": [
        "categorical_columns_size = [len(df[column].cat.categories) for column in categorical_columns]\n",
        "categorical_embedding_sizes = [(col_size, min(50, (col_size + 1) // 2)) for col_size in categorical_columns_size]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLJEKKoLhQAz"
      },
      "source": [
        "# CREATE PYTORCH DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaVwMCL64ttq"
      },
      "source": [
        "train_tensor_dataset = TensorDataset(tensor_x_train_cat, tensor_x_train_num, tensor_y_train)\n",
        "train_loader = DataLoader(dataset=train_tensor_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsI8RQbZhriV"
      },
      "source": [
        "# DEFINE NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHX1GpfYkdHd"
      },
      "source": [
        "![](https://yashuseth.files.wordpress.com/2018/07/model1.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_1m9m_3Msst"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, embedding_size, input_size, num_numerical_cols, layers, ps):\n",
        "    super().__init__()\n",
        "\n",
        "    self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
        "    self.emb_drop = nn.Dropout(hp_emb_drop)\n",
        "\n",
        "    self.bn_cont = nn.BatchNorm1d(num_numerical_cols)\n",
        "\n",
        "    layerlist = []\n",
        "    for i, elem in enumerate(layers):\n",
        "      layerlist.append(nn.Linear(input_size, elem))\n",
        "      layerlist.append(nn.ReLU(inplace=True))\n",
        "      layerlist.append(nn.BatchNorm1d(layers[i]))\n",
        "      layerlist.append(nn.Dropout(ps[i]))\n",
        "      input_size = elem\n",
        "    layerlist.append(nn.Linear(layers[-1], 1))\n",
        "\n",
        "    self.layers = nn.Sequential(*layerlist)\n",
        "\n",
        "  def forward(self, x_c, x_n):\n",
        "\n",
        "    embeddings = [e(x_c[:,i].long()) for i, e in enumerate(self.all_embeddings)]\n",
        "\n",
        "    x = torch.cat(embeddings, 1)\n",
        "    x = self.emb_drop(x)\n",
        "\n",
        "    x_n = self.bn_cont(x_n)\n",
        "\n",
        "    x = torch.cat([x, x_n], 1)\n",
        "    x = self.layers(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHlbmRfnhjA"
      },
      "source": [
        "# INSTANTIATE NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBAifb1TTjhG"
      },
      "source": [
        "num_numerical_cols = tensor_x_train_num.shape[1]\n",
        "\n",
        "num_categorical_cols = sum((nf for ni, nf in categorical_embedding_sizes))\n",
        "initial_input_size = num_categorical_cols + num_numerical_cols\n",
        "\n",
        "model = Model(categorical_embedding_sizes, initial_input_size, num_numerical_cols, layers=hp_layers, ps=hp_ps)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hp_lr)\n",
        "model.to(device)\n",
        "tot_losses = []"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTtyHh92n4Ac"
      },
      "source": [
        "# TRAIN NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6yyOYgr5bZP"
      },
      "source": [
        "start_training = generate_timestamp()\n",
        "\n",
        "for epoch in range(hp_epochs):\n",
        "  train_losses = []\n",
        "  for x_cat, x_num, y in train_loader:\n",
        "    y_pred = model(x_cat, x_num)\n",
        "    single_loss = torch.sqrt(loss_function(y_pred.squeeze(), y))\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward() \n",
        "    optimizer.step()\n",
        "    train_losses.append(single_loss.item())\n",
        "  epoch_loss = 1.0 * sum(train_losses) / len(train_losses)\n",
        "  tot_losses.append(epoch_loss)\n",
        "  print(\"epoch: \" + str(epoch) + \"\\tloss: \" + str(epoch_loss))\n",
        "plt.plot(tot_losses)\n",
        "plt.show()\n",
        "\n",
        "end_training = generate_timestamp()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d88QHnDQvGnQ"
      },
      "source": [
        "# VALIDATE NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozr6OavjNgrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b20b4d7-21af-40fa-fb8a-6a3d484c6cab"
      },
      "source": [
        "validation_tensor_dataset = TensorDataset(tensor_x_valid_cat, tensor_x_valid_num, tensor_y_valid)\n",
        "validation_loader = DataLoader(dataset=validation_tensor_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "valid_losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x_cat, x_num, y in validation_loader:\n",
        "    y_valid = model(x_cat, x_num)\n",
        "    validation_loss = torch.sqrt(loss_function(y_valid.squeeze(), y))\n",
        "    valid_losses.append(validation_loss.item())\n",
        "  valid_loss = str(round(1.0 * sum(valid_losses) / len(valid_losses), 5))\n",
        "  print(\"loss: \" + valid_loss)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.23926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q9QC2cAvNrS"
      },
      "source": [
        "# MAKE PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbY5ybTLJpd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1c56cf7-c626-40c4-fa8d-621a64aaa3c5"
      },
      "source": [
        "with torch.no_grad():\n",
        "  y_test = model(tensor_x_test_cat, tensor_x_test_num)\n",
        "pd.DataFrame(y_test).astype(\"float\").hist(bins=1000)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f6783b1c4a8>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5CHX5POvVYB"
      },
      "source": [
        "# SAVE PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc2BwhwKoHDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45994cb2-01e6-412a-b05f-dacddeac95ad"
      },
      "source": [
        "prediction_id = ''.join(random.choice(letters) for i in range(5))\n",
        "prediction_df = pd.DataFrame(y_test).astype(\"float\")\n",
        "x_scaled = min_max_scaler.fit_transform(prediction_df)\n",
        "prediction_df = pd.DataFrame(x_scaled)\n",
        "prediction_df = pd.concat([prediction_df, application_test_df['SK_ID_CURR']], axis=1)\n",
        "prediction_df.columns = ['TEMP_TARGET', 'SK_ID_CURR']\n",
        "prediction_df['TARGET'] = round(prediction_df['TEMP_TARGET'], 1)\n",
        "prediction_df = prediction_df[['SK_ID_CURR', 'TARGET']]\n",
        "prediction_df.to_csv('/drive/My Drive/pycharm_colab_training/kaggle/HomeCreditDefaultRisk/submissions/' + prediction_id + '.csv', index=False)\n",
        "test_target_mean = str(round(prediction_df['TARGET'].mean(), 3))\n",
        "test_distrbution = prediction_df.groupby(by=['TARGET'])['TARGET'].count()\n",
        "print(\"test_target_mean:\", test_target_mean)\n",
        "print(test_distrbution.to_string(header=False))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_target_mean: 0.38\n",
            "0.00000       16\n",
            "0.10000      808\n",
            "0.20000     6772\n",
            "0.30000    12488\n",
            "0.40000    15915\n",
            "0.50000     8191\n",
            "0.60000     3379\n",
            "0.70000      888\n",
            "0.80000      261\n",
            "0.90000       24\n",
            "1.00000        2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2sCUB3aOdy"
      },
      "source": [
        "# SAVE DATA TO SHEET\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA80EJskMH6E",
        "outputId": "412b0f26-ac76-42ae-d573-132231626fa9"
      },
      "source": [
        "model_values_dict = {\n",
        "  'ID': prediction_id,\n",
        "  'start_training': start_training,\n",
        "  'end_training': end_training,\n",
        "  'perc_test_size': hp_test_size,\n",
        "  'emb_drop': hp_emb_drop,\n",
        "  'layers': '\\n'.join([str(i) for i in hp_layers]),\n",
        "  'ps': '\\n'.join([str(i) for i in hp_ps]),\n",
        "  'lr': hp_lr,\n",
        "  'epochs': hp_epochs,\n",
        "  'train_losses': '\\n'.join([str(round(i, 5)) for i in tot_losses]),\n",
        "  'valid_loss': valid_loss,\n",
        "  'test_target_mean': test_target_mean,\n",
        "  'test_distrbution': test_distrbution.to_string(header=False),\n",
        "  'numerical_columns': len(numerical_columns),\n",
        "  'categorical_columns': len(categorical_columns),\n",
        "  'model_parameters': str(model.parameters)\n",
        "}\n",
        "\n",
        "next_row = get_next_row(sheet)\n",
        "cells = sheet.range('A' + next_row + ':P' + next_row)\n",
        "model_values_list = list(model_values_dict.values())\n",
        "for i, cell in enumerate(cells):\n",
        "  cell.value = model_values_list[i]\n",
        "sheet.update_cells(cells)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1M-CqsTbBu7ScY4mZBcpI8kPbI7F-BE8aPTC4UknumYk',\n",
              " 'updatedCells': 16,\n",
              " 'updatedColumns': 16,\n",
              " 'updatedRange': 'Data!A5:P5',\n",
              " 'updatedRows': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    }
  ]
}