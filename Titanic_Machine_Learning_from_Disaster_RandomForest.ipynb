{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic: Machine Learning from Disaster_RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd215vr2mpz3s5zuFxSTzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robimalco/colab/blob/main/Titanic_Machine_Learning_from_Disaster_RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Gab4RH7kRj"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCh6gWUa8Ue_"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3MikqX8W3M"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZqQJv1X8ZYi"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx98snIy8diy"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xRj1RU8h_m"
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO57DG0g80_w"
      },
      "source": [
        "!mkdir train\n",
        "!unzip train.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LJhFeCF_Ie7"
      },
      "source": [
        "# START"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5ybphV_KqE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "121_vnK4_q1c"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "train_df['df_source'] = 'train.csv'\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df['df_source'] = 'test.csv'\n",
        "\n",
        "total_df = pd.concat([train_df, test_df])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e457G6xW3Wyi"
      },
      "source": [
        "# Diplay null values of each column\n",
        "total_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eDuPvxoHeeH"
      },
      "source": [
        "# Manage names creating TitleCluster\n",
        "\n",
        "Title_Dictionary = {\n",
        "    \"Capt\": \"Officer\",\n",
        "    \"Col\": \"Officer\",\n",
        "    \"Major\": \"Officer\",\n",
        "    \"Jonkheer\": \"Royalty\",\n",
        "    \"Don\": \"Royalty\",\n",
        "    \"Sir\" : \"Royalty\",\n",
        "    \"Dr\": \"Officer\",\n",
        "    \"Rev\": \"Officer\",\n",
        "    \"the Countess\":\"Royalty\",\n",
        "    \"Mme\": \"Mrs\",\n",
        "    \"Mlle\": \"Miss\",\n",
        "    \"Ms\": \"Mrs\",\n",
        "    \"Mr\" : \"Mr\",\n",
        "    \"Mrs\" : \"Mrs\",\n",
        "    \"Dona\" : \"Mrs\",\n",
        "    \"Miss\" : \"Miss\",\n",
        "    \"Master\" : \"Master\",\n",
        "    \"Lady\" : \"Royalty\"\n",
        "}\n",
        "\n",
        "def get_titles(x):\n",
        "    title = x['Name'].split(',')[1].split('.')[0].strip()\n",
        "    return Title_Dictionary[title]\n",
        "total_df['TitleCluster'] = total_df.apply(get_titles, axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0b6KaUQJlx"
      },
      "source": [
        "# Manage missing age and create AgeCluster\n",
        "\n",
        "def fill_missing_age(x):\n",
        "    age = x['Age']\n",
        "    if np.isnan(age):\n",
        "      return total_df[\n",
        "        (total_df['TitleCluster'] == x['TitleCluster']) &\n",
        "        (total_df['Sex'] == x['Sex']) &\n",
        "        (total_df['Pclass'] == x['Pclass'])\n",
        "      ]['Age'].median()\n",
        "    else:\n",
        "      return age\n",
        "\n",
        "total_df['Age'] = total_df.apply(fill_missing_age, axis=1)\n",
        "\n",
        "def cluster_age(x):\n",
        "    age = x['Age']\n",
        "    if age < 5:\n",
        "      return 0\n",
        "    elif age < 10:\n",
        "      return 1\n",
        "    elif age < 20:\n",
        "      return 2\n",
        "    elif age < 30:\n",
        "      return 3\n",
        "    elif age < 40:\n",
        "      return 4\n",
        "    elif age < 50:\n",
        "      return 5\n",
        "    elif age < 60:\n",
        "      return 6\n",
        "    else:\n",
        "      return 7\n",
        "total_df['AgeCluster'] = total_df.apply(cluster_age, axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwfu7steBeOc"
      },
      "source": [
        "# Manage tickets\n",
        "\n",
        "total_df['TicketCluster'] = total_df['Ticket'].str[0]\n",
        "total_df['TicketCluster'] = np.where(total_df[\"TicketCluster\"].str.isdigit(), \"X\", total_df[\"TicketCluster\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6W3m_4CSCZj"
      },
      "source": [
        "# Manage missing embarked\n",
        "\n",
        "def fill_missing_embarked(x):\n",
        "    embarked = x['Embarked']\n",
        "    if embarked != embarked:\n",
        "      return \"X\"\n",
        "    else:\n",
        "      return embarked\n",
        "\n",
        "total_df['Embarked'] = total_df.apply(fill_missing_embarked, axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUsfiwmU9RJJ"
      },
      "source": [
        "# Manage family\n",
        "\n",
        "def cluster_family(x):\n",
        "    pcSib = x['SibSp'] + x['Pclass'] + 1\n",
        "    if pcSib < 2:\n",
        "        return 'Single'\n",
        "    elif pcSib == 2:\n",
        "        return 'Couple'\n",
        "    elif pcSib <= 4:\n",
        "        return 'InterM'\n",
        "    else:\n",
        "        return 'Large'\n",
        "    \n",
        "total_df['FamilyCluster'] = total_df.apply(cluster_family, axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eiBZHlADF7E"
      },
      "source": [
        "# Manage fare\n",
        "\n",
        "def fill_missing_fare(x):\n",
        "  fare = x['Fare']\n",
        "  if fare == 0:\n",
        "      return total_df[\n",
        "        (total_df['TitleCluster'] == x['TitleCluster']) &\n",
        "        (total_df['Sex'] == x['Sex']) &\n",
        "        (total_df['Pclass'] == x['Pclass'])\n",
        "      ]['Fare'].median()\n",
        "  else:\n",
        "    return fare\n",
        "\n",
        "total_df['Fare'] = total_df.apply(fill_missing_fare, axis=1)\n",
        "\n",
        "def cluster_fare(x):\n",
        "    fare = x['Fare']\n",
        "    if fare < 51:\n",
        "        return 0\n",
        "    elif fare < 101:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "total_df['FareCluster'] = total_df.apply(cluster_fare, axis=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk_7dg-7_u8m"
      },
      "source": [
        "categorical_columns = ['Survived', 'df_source', 'Pclass', 'Sex', 'Embarked', 'AgeCluster', 'FareCluster', 'TicketCluster', 'TitleCluster', 'FamilyCluster']\n",
        "cat_total_df = total_df[categorical_columns]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqg65ayzyjYY"
      },
      "source": [
        "dummy_total_df = pd.get_dummies(cat_total_df)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwpOqdIyjMG"
      },
      "source": [
        "train_total_df = dummy_total_df[dummy_total_df['df_source_train.csv'] == 1]\n",
        "test_total_df = dummy_total_df[dummy_total_df['df_source_test.csv'] == 1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWqcPDO9zQB5"
      },
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "train_total_df.Survived = train_total_df.Survived.astype('int')\n",
        "xtrain = train_total_df.drop(\"Survived\", axis=1)\n",
        "ytrain = train_total_df['Survived']\n",
        "xtest = test_total_df.drop(\"Survived\", axis=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckWjNr30zfVA"
      },
      "source": [
        "# Random Forest\n",
        "RF = RandomForestClassifier(random_state=1)\n",
        "PRF = [\n",
        "  {\n",
        "    'n_estimators': [10,100],\n",
        "    'max_depth': [3,6],\n",
        "    'criterion': ['gini','entropy']\n",
        "  }\n",
        "]\n",
        "GSRF = GridSearchCV(\n",
        "    estimator=RF, \n",
        "    param_grid=PRF,\n",
        "    scoring='accuracy', \n",
        "    cv=2\n",
        ")\n",
        "scores_rf = cross_val_score(\n",
        "    GSRF,\n",
        "    xtrain,\n",
        "    ytrain,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "np.mean(scores_rf)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wycu3MPO0hkD"
      },
      "source": [
        "# SVM (Support Vector Machine)\n",
        "svc = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(random_state=1)\n",
        ")\n",
        "r = [0.0001, 0.001, 0.1, 1, 10, 50, 100]\n",
        "PSVM = [\n",
        "  {\n",
        "    'svc__C': r,\n",
        "    'svc__kernel': ['linear']\n",
        "  },\n",
        "  {\n",
        "    'svc__C': r,\n",
        "    'svc__gamma': r,\n",
        "    'svc__kernel': ['rbf']\n",
        "  }\n",
        "]\n",
        "GSSVM = GridSearchCV(\n",
        "    estimator=svc, \n",
        "    param_grid=PSVM, \n",
        "    scoring='accuracy',\n",
        "    cv=2\n",
        ")\n",
        "scores_svm = cross_val_score(\n",
        "    GSSVM, \n",
        "    xtrain.astype(float), \n",
        "    ytrain,scoring='accuracy', \n",
        "    cv=5\n",
        ")\n",
        "np.mean(scores_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giuPSBH91-Un"
      },
      "source": [
        "model = GSSVM.fit(xtrain, ytrain)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfSkbP2z1-nK"
      },
      "source": [
        "pred = model.predict(xtest)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXGTfUDp2DCr",
        "outputId": "2605c65b-1d04-428c-cb14-f6dcf06a91b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "submission_df = pd.DataFrame({'PassengerId':test_df['PassengerId'], 'Survived':pred})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2622a85b-8fb1-43ad-bcff-bdae76c65c7a\", \"submission.csv\", 2839)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}