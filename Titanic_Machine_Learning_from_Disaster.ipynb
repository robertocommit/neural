{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic: Machine Learning from Disaster.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUlSYrX5PKdRmsYushYWdi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robimalco/colab/blob/main/Titanic_Machine_Learning_from_Disaster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Gab4RH7kRj"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCh6gWUa8Ue_"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3MikqX8W3M"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZqQJv1X8ZYi"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx98snIy8diy"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xRj1RU8h_m"
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO57DG0g80_w"
      },
      "source": [
        "!mkdir train\n",
        "!unzip train.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LJhFeCF_Ie7"
      },
      "source": [
        "# START"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5ybphV_KqE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "121_vnK4_q1c"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "train_df['df_source'] = 'train.csv'\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df['df_source'] = 'test.csv'\n",
        "\n",
        "total_df = pd.concat([train_df, test_df])"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e457G6xW3Wyi"
      },
      "source": [
        "# Diplay null values of each column\n",
        "total_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eDuPvxoHeeH"
      },
      "source": [
        "# Manage titles\n",
        "def get_title(name):\n",
        "    if '.' in name:\n",
        "        return name.split(',')[1].split('.')[0].strip()\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "def replace_titles(x): # Normalize the titles\n",
        "    title = x['TitleCluster']\n",
        "    if title in ['Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n",
        "        return 'Mr'\n",
        "    elif title in ['the Countess', 'Mme', 'Lady']:\n",
        "        return 'Mrs'\n",
        "    elif title in ['Mlle', 'Ms']:\n",
        "        return 'Miss'\n",
        "    elif title =='Dr':\n",
        "        if x['Sex']=='male':\n",
        "            return 'Mr'\n",
        "        else:\n",
        "            return 'Mrs'\n",
        "    else:\n",
        "        return title\n",
        "\n",
        "total_df['TitleCluster'] = total_df['Name'].map(lambda x: get_title(x))\n",
        "total_df['TitleCluster'] = total_df.apply(replace_titles, axis=1)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwfu7steBeOc"
      },
      "source": [
        "# Manage tickets\n",
        "total_df['TicketCluster'] = total_df['Ticket'].str[0]\n",
        "total_df['TicketCluster'] = np.where(total_df[\"TicketCluster\"].str.isdigit(), \"X\", total_df[\"TicketCluster\"])"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0b6KaUQJlx"
      },
      "source": [
        "# Manage missing age\n",
        "def fill_missing_age(x):\n",
        "    age = x['Age']\n",
        "    title = x['TitleCluster']\n",
        "    if np.isnan(age):\n",
        "      if title == 'Dona':\n",
        "          return total_df[total_df['TitleCluster'] == 'Dona']['Age'].median()\n",
        "      elif title == 'Master':\n",
        "          return total_df[total_df['TitleCluster'] == 'Master']['Age'].median()\n",
        "      elif title == 'Miss':\n",
        "          return total_df[total_df['TitleCluster'] == 'Miss']['Age'].median()\n",
        "      elif title == 'Mr':\n",
        "        return total_df[total_df['TitleCluster'] == 'Mr']['Age'].median()\n",
        "      elif title == 'Mrs':\n",
        "        return total_df[total_df['TitleCluster'] == 'Mrs']['Age'].median()\n",
        "    else:\n",
        "      return age\n",
        "\n",
        "total_df['Age'] = total_df.apply(fill_missing_age, axis=1)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6W3m_4CSCZj"
      },
      "source": [
        "# Manage missing Embarked\n",
        "def fill_missing_embarked(x):\n",
        "    embarked = x['Embarked']\n",
        "    if embarked != embarked:\n",
        "      return \"X\"\n",
        "    else:\n",
        "      return embarked\n",
        "\n",
        "total_df['Embarked'] = total_df.apply(fill_missing_embarked, axis=1)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUsfiwmU9RJJ"
      },
      "source": [
        "# Manage Pclass / SibSp\n",
        "def family(x):\n",
        "    pclass = x['Pclass']\n",
        "    sibSp = x['SibSp']\n",
        "    pcSib = sibSp + pclass\n",
        "    if pcSib < 2:\n",
        "        return 'Single'\n",
        "    elif pcSib == 2:\n",
        "        return 'Couple'\n",
        "    elif pcSib <= 4:\n",
        "        return 'InterM'\n",
        "    else:\n",
        "        return 'Large'\n",
        "    \n",
        "total_df['FamilyCluster'] = total_df.apply(family, axis=1)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eiBZHlADF7E"
      },
      "source": [
        "total_df['AgeCluster'] = pd.cut(total_df['Age'], bins=[0, 5, 10, 20, 30, 40, 50, 60, 70, 81], include_lowest=True, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "total_df['FareCluster'] = pd.cut(total_df['Fare'], bins=[0, 51, 101, 2000], include_lowest=True, labels=[0, 1, 2])"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk_7dg-7_u8m"
      },
      "source": [
        "categorical_columns = ['df_source', 'Pclass', 'Sex', 'AgeCluster', 'FareCluster', 'Embarked', 'TicketCluster', 'TitleCluster', 'FamilyCluster']\n",
        "cat_total_df = total_df[categorical_columns]"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMqMTS4MAy_m"
      },
      "source": [
        "for column in categorical_columns:\n",
        "  cat_total_df[column] = LabelEncoder().fit_transform(cat_total_df[column])\n",
        "for column in categorical_columns:\n",
        "  cat_total_df[column] = cat_total_df[column].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAauVM0xKQYZ"
      },
      "source": [
        "train_total_df = cat_total_df[cat_total_df['df_source'] == 1]\n",
        "test_total_df = cat_total_df[cat_total_df['df_source'] == 0]"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDuPpZ2DGtGE"
      },
      "source": [
        "def create_categorical_stack(input_df):\n",
        "  stack = []\n",
        "  for column in categorical_columns:\n",
        "    temp_stack = input_df[column].cat.codes.values\n",
        "    stack.append(temp_stack)\n",
        "  return np.stack(stack, 1)\n",
        "\n",
        "train_categorical_df = create_categorical_stack(train_total_df)\n",
        "test_categorical_df = create_categorical_stack(test_total_df)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00YhiAHUOWf6"
      },
      "source": [
        "tensor_train = torch.tensor(train_categorical_df, dtype=torch.int64)\n",
        "tensor_output = torch.tensor(train_df['Survived']).flatten()\n",
        "\n",
        "tensor_test = torch.tensor(test_categorical_df, dtype=torch.int64)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_BQPREIO9x6"
      },
      "source": [
        "total_records_train = len(train_total_df)\n",
        "test_records_train = int(total_records_train * 0.2)\n",
        "\n",
        "tensor_train_data = tensor_train[:total_records_train-test_records_train]\n",
        "tensor_train_output = tensor_output[:total_records_train-test_records_train]\n",
        "\n",
        "tensor_test_data = tensor_train[total_records_train-test_records_train:total_records_train]\n",
        "tensor_test_output = tensor_output[total_records_train-test_records_train:total_records_train]"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6k2j2iWLdEm"
      },
      "source": [
        "categorical_columns_size = [len(cat_total_df[column].astype('category').cat.categories) for column in categorical_columns]\n",
        "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_columns_size]"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGmxMRzyPnPS"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, embedding_sizes):\n",
        "    super().__init__()\n",
        "    self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
        "    n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
        "    self.lin1 = nn.Linear(n_emb, 200)\n",
        "    self.lin2 = nn.Linear(200, 70)\n",
        "    self.lin3 = nn.Linear(70, 2)\n",
        "    self.bn1 = nn.BatchNorm1d(n_emb)\n",
        "    self.bn2 = nn.BatchNorm1d(200)\n",
        "    self.bn3 = nn.BatchNorm1d(70)\n",
        "    self.emb_drop = nn.Dropout(0.6)\n",
        "    self.drops = nn.Dropout(0.3)\n",
        "    self.sig = nn.Sigmoid()\n",
        "  def forward(self, x_cat):\n",
        "    x = [e(x_cat[:,i]) for i, e in enumerate(self.embeddings)]\n",
        "    x = torch.cat(x, 1)\n",
        "    x = self.emb_drop(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.lin1(x)\n",
        "    x = self.drops(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = self.drops(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.lin3(x)\n",
        "    x = self.sig(x)\n",
        "    return x"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc-kqrVDs90n"
      },
      "source": [
        "model = Model(categorical_embedding_sizes)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVCB45E088ol",
        "outputId": "14c5cce6-c665-43b9-b59c-479de0a6dd29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 300\n",
        "aggregated_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    i += 1\n",
        "    y_pred = model(tensor_train_data)\n",
        "    single_loss = loss_function(y_pred, tensor_train_output)\n",
        "    aggregated_losses.append(single_loss)\n",
        "    if i%200 == 1:\n",
        "        print(\"epoch: \" + str(i) + \"\\tloss: \" + str(single_loss.item()))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"epoch: \" + str(i) + \"\\tloss: \" + str(single_loss.item()))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\tloss: 0.7078914642333984\n",
            "epoch: 201\tloss: 0.5226251482963562\n",
            "epoch: 300\tloss: 0.513256311416626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-NJLACm9yFI",
        "outputId": "2de4a706-4a60-4b78-b0bf-0d01cc7098b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    y_val = model(tensor_test_data)\n",
        "    loss = loss_function(y_val, tensor_test_output)\n",
        "print(\"Loss: \" + str(loss))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(0.4745)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCcHJKfr-511",
        "outputId": "d2fb9de4-d9da-4219-b761-1bfe22edbbb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "y_val_sklearn = np.argmax(y_val, axis=1)\n",
        "\n",
        "print(\"\\nconfusion_matrix\")\n",
        "print(confusion_matrix(tensor_test_output, y_val_sklearn))\n",
        "print(\"\\nclassification_report\")\n",
        "print(classification_report(tensor_test_output, y_val_sklearn))\n",
        "print(\"\\naccuracy_score\")\n",
        "print(accuracy_score(tensor_test_output, y_val_sklearn))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "confusion_matrix\n",
            "[[102  13]\n",
            " [ 17  46]]\n",
            "\n",
            "classification_report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       115\n",
            "           1       0.78      0.73      0.75        63\n",
            "\n",
            "    accuracy                           0.83       178\n",
            "   macro avg       0.82      0.81      0.81       178\n",
            "weighted avg       0.83      0.83      0.83       178\n",
            "\n",
            "\n",
            "accuracy_score\n",
            "0.8314606741573034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HAQNxE5TirH",
        "outputId": "555ddc23-bbce-49c4-be2c-aff9afe97058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    y_pred = model(tensor_test)\n",
        "print(\"Loss: \" + str(loss))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(0.4745)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR8b6mmo6OKL"
      },
      "source": [
        "values, labels = torch.max(y_pred, 1)\n",
        "survived = labels.data.numpy()\n",
        "submission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': survived})\n",
        "submission_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1JmP5XNgKEz",
        "outputId": "7419073f-77e3-42b2-bc52-4619d26ebd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8ea633f2-4a34-4339-b6cb-770fd4749fc1\", \"submission.csv\", 2839)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}